<!DOCTYPE HTML>
<html lang="en">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="hands on: 15 sequence, Tech Blog">
    <meta name="description" content="">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>hands on: 15 sequence | Tech Blog</title>
    <link rel="icon" type="image/jpeg" href="/Blog/medias/teemo.jpeg">

    <link rel="stylesheet" type="text/css" href="/Blog/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="/Blog/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/Blog/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/Blog/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/Blog/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/Blog/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/Blog/css/my.css">

    <script src="/Blog/libs/jquery/jquery.min.js"></script>

<meta name="generator" content="Hexo 5.1.1"><link rel="stylesheet" href="/Blog/css/prism-tomorrow.css" type="text/css"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Blog/" class="waves-effect waves-light">
                    
                    <img src="/Blog/medias/teemo.jpeg" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Tech Blog</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Blog/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>Index</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Blog/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>Tags</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Blog/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>Categories</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Blog/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>Archives</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Blog/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>About</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Blog/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>Contact</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Blog/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>Friends</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="Search" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Blog/medias/teemo.jpeg" class="logo-img circle responsive-img">
        
        <div class="logo-name">Tech Blog</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Blog/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			Index
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Blog/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			Tags
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Blog/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			Categories
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Blog/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			Archives
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Blog/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			About
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Blog/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			Contact
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Blog/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			Friends
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/csy99/Blog" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork My Blog
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/csy99/Blog" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork My Blog" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/Blog/medias/featureimages/0.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">hands on: 15 sequence</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="/Blog/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        margin: 35px 0 15px 0;
        padding-left: 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        height: calc(100vh - 250px);
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;

        position: absolute;
        right: 23.5vw;
        display: block;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Blog/tags/DL/">
                                <span class="chip bg-color">DL</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Blog/categories/Deep-Learning/" class="post-category">
                                Deep Learning
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>Publish Date:&nbsp;&nbsp;
                    2020-08-16
                </div>
                

                

                

                

                
            </div>
        </div>
        <hr class="clearfix">
        <div class="card-content article-card-content">
            <div id="articleContent">
                <h1 id="RNN"><a href="#RNN" class="headerlink" title="RNN"></a>RNN</h1><p>RN: recurrent neuron</p>
<p>RNN has connections pointing backward. At time step t, RN receives the inputs $x_t$ as well as its own output from the previous time step, $y_{(t-1)}$. Thus, each RN has two sets of weights. We can represent it against the time axis (unrolling the network through time). </p>
<h3 id="Memory-Cells"><a href="#Memory-Cells" class="headerlink" title="Memory Cells"></a>Memory Cells</h3><p>A part of a NN that preserves some state across time steps is called a memory cell. RN is capable of learning short patterns. </p>
<h3 id="Input-and-Output-Sequences"><a href="#Input-and-Output-Sequences" class="headerlink" title="Input and Output Sequences"></a>Input and Output Sequences</h3><p>An RNN can simultaneously take a seq of inputs and produce a seq of outputs. This type of seq-to-seq network is useful for predicting time series. </p>
<p>Alternatively, we can ignore all outputs except for the last one. This seq-to-vec network can be used to tackle classification/regression problem. </p>
<p>Conversely, we can feed the network the input vec at each time step and let it output a seq. This vect-to-seq network can be used to tackle problems like sequence generating (e.g., outputting a caption for an image). </p>
<h3 id="Forecasting"><a href="#Forecasting" class="headerlink" title="Forecasting"></a>Forecasting</h3><p>Univariate: one value per time step </p>
<p>BPTT: backprop through time. </p>
<p>We are using a time series generated by generate_time_series() as an example. </p>
<pre class=" language-Python"><code class="language-Python">def generate_time_series(batch_size, n_steps):
    freq1, freq2, offset1, offset2 = np.random.rand(4, batch_size, 1)
    time = np.linspace(0, 1, n_steps)
    series = 0.5 * np.sin((time-offset1)*(freq1*10+10))
    series += 0.2 * np.sin((time-offset2)*(freq2*10+20))
    series += 0.1 * (np.random.rand(batch_size, n_steps)-0.5)
    return series[...,np.newaxis].astype(np.float32)</code></pre>
<p>The input features are generally represented as 3D arrays [batch size, time steps, dimensionality]. </p>
<p>Create a training set. </p>
<pre class=" language-python"><code class="language-python">n_steps <span class="token operator">=</span> <span class="token number">50</span>
seres <span class="token operator">=</span> generate_time_eries<span class="token punctuation">(</span><span class="token number">10000</span><span class="token punctuation">,</span> n_steps<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span>
xtrain<span class="token punctuation">,</span> ytrain <span class="token operator">=</span> seres<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">7000</span><span class="token punctuation">,</span> <span class="token punctuation">:</span>n_steps<span class="token punctuation">]</span><span class="token punctuation">,</span> seires<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">7000</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
xval<span class="token punctuation">,</span> yval <span class="token operator">=</span> seres<span class="token punctuation">[</span><span class="token number">7000</span><span class="token punctuation">:</span><span class="token number">9000</span><span class="token punctuation">,</span> <span class="token punctuation">:</span>n_steps<span class="token punctuation">]</span><span class="token punctuation">,</span> seires<span class="token punctuation">[</span><span class="token number">7000</span><span class="token punctuation">:</span><span class="token number">9000</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
xtest<span class="token punctuation">,</span> ytest <span class="token operator">=</span> seres<span class="token punctuation">[</span><span class="token number">9000</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span>n_steps<span class="token punctuation">]</span><span class="token punctuation">,</span> seires<span class="token punctuation">[</span><span class="token number">9000</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span></code></pre>
<h3 id="Baseline-Metrics"><a href="#Baseline-Metrics" class="headerlink" title="Baseline Metrics"></a>Baseline Metrics</h3><p>The simplest approach is to predict the last value in each series (naive forecasting), which is surprisingly difficult to outperform. </p>
<pre class=" language-python"><code class="language-python">y_pred <span class="token operator">=</span> xval<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>keras<span class="token punctuation">.</span>losses<span class="token punctuation">.</span>mean_squared_error<span class="token punctuation">(</span>yval<span class="token punctuation">,</span> y_pred<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre>
<p>Another simple approach is to use a fully connected network. </p>
<pre class=" language-python"><code class="language-python">model <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>
    Flatten<span class="token punctuation">(</span>input_shape<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">50</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Dense<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre>
<h3 id="Simple-RNN"><a href="#Simple-RNN" class="headerlink" title="Simple RNN"></a>Simple RNN</h3><p>We do not need to specify the length of the input sequences. To process any number of time steps, we set the first input dimension to None. </p>
<p>Use a tanh activation funciton by default. </p>
<pre class=" language-python"><code class="language-python">model <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>
    keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>SimpleRNN<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> input_shape<span class="token operator">=</span><span class="token punctuation">[</span>None<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre>
<h3 id="Deep-RNN"><a href="#Deep-RNN" class="headerlink" title="Deep RNN"></a>Deep RNN</h3><p>Stack. </p>
<pre class=" language-python"><code class="language-python">model <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>
    keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>SimpleRNN<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span> return_sequences<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> input_shape<span class="token operator">=</span><span class="token punctuation">[</span>None<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>SimpleRNN<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span> return_sequences<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>SimpleRNN<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre>
<p>Make sure to set <strong>return_sequences</strong> to True for all recurrent layers except the last one (if only care about the last output). </p>
<p>Note that the last layer has only a single unit, because we want to forecast a univariate time series. This means we must have a single output value per time step. We can replace it with a Dense layer. </p>
<h3 id="Forecasting-Several-Time-Steps-Ahead"><a href="#Forecasting-Several-Time-Steps-Ahead" class="headerlink" title="Forecasting Several Time Steps Ahead"></a>Forecasting Several Time Steps Ahead</h3><p>We can predict the next 10 steps just like below. </p>
<pre class=" language-python"><code class="language-python">series <span class="token operator">=</span> generate_time_series<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> n_steps<span class="token operator">+</span><span class="token number">10</span><span class="token punctuation">)</span>
X_new<span class="token punctuation">,</span> Y_new <span class="token operator">=</span> series<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span>n_steps<span class="token punctuation">]</span><span class="token punctuation">,</span> sries<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> n_steps<span class="token punctuation">:</span><span class="token punctuation">]</span>
X <span class="token operator">=</span> X_new
<span class="token keyword">for</span> step_ahead <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    y_pred_one <span class="token operator">=</span> model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> step_ahead<span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>newaxis<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>
    X <span class="token operator">=</span> np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span><span class="token punctuation">[</span>X<span class="token punctuation">,</span> y_pred_one<span class="token punctuation">]</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
Y_pred <span class="token operator">=</span> X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> n_steps<span class="token punctuation">:</span><span class="token punctuation">]</span></code></pre>
<p>The prediction for the next step will usually be more accurate than the predictions for later time steps, since the errs might accumulate. </p>
<p>We can also train RNN to predict all 10 next val at once. </p>
<pre class=" language-python"><code class="language-python">series <span class="token operator">=</span> generate_time_series<span class="token punctuation">(</span><span class="token number">10000</span><span class="token punctuation">,</span> n_steps<span class="token operator">+</span><span class="token number">10</span><span class="token punctuation">)</span>
xtrain<span class="token punctuation">,</span> ytrain <span class="token operator">=</span> series<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">7000</span><span class="token punctuation">,</span> <span class="token punctuation">:</span>n_steps<span class="token punctuation">]</span><span class="token punctuation">,</span> series<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">7000</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span>
xval<span class="token punctuation">,</span> yval <span class="token operator">=</span> series<span class="token punctuation">[</span><span class="token number">7000</span><span class="token punctuation">:</span><span class="token number">9000</span><span class="token punctuation">,</span> <span class="token punctuation">:</span>n_steps<span class="token punctuation">]</span><span class="token punctuation">,</span> series<span class="token punctuation">[</span><span class="token number">7000</span><span class="token punctuation">:</span><span class="token number">9000</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span>
xtest<span class="token punctuation">,</span> ytest <span class="token operator">=</span> series<span class="token punctuation">[</span><span class="token number">9000</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span>n_steps<span class="token punctuation">]</span><span class="token punctuation">,</span> series<span class="token punctuation">[</span><span class="token number">9000</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span>

model <span class="token operator">=</span> Sequentail<span class="token punctuation">(</span><span class="token punctuation">[</span>
    SimpleRNN<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span> return_sequences<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> input_shape<span class="token operator">=</span><span class="token punctuation">[</span>None<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    SimpleRNN<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
    Dense<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre>
<p>Instead of training the model to forecast the next 10 values only at very last time step, we can train it to forecast the next 10 values at each time step. This will stabilize and speed up training. </p>
<p>At t=0, the model will output a vector containing the forecasts for time steps 1 to 10. At t=1, it will forecast steps 2 to 11. </p>
<pre class=" language-python"><code class="language-python">Y <span class="token operator">=</span> np<span class="token punctuation">.</span>empty<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">10000</span><span class="token punctuation">,</span> n_steps<span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> step_ahead <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    Y<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> step_ahead<span class="token number">-1</span><span class="token punctuation">]</span> <span class="token operator">=</span> series<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> step_ahead<span class="token punctuation">:</span>step_ahead<span class="token operator">+</span>n_steps<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span>

Ytrain <span class="token operator">=</span> Y<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">7000</span><span class="token punctuation">]</span>
Yval <span class="token operator">=</span> Y<span class="token punctuation">[</span><span class="token number">7000</span><span class="token punctuation">:</span><span class="token number">9000</span><span class="token punctuation">]</span>
Ytest <span class="token operator">=</span> Y<span class="token punctuation">[</span><span class="token number">9000</span><span class="token punctuation">:</span><span class="token punctuation">]</span></code></pre>
<p>This turns our model into seq-to-seq model. We must apply the output Dense layer at every time step. In Keras, <code>TimeDistributed</code> layer wraps any layer (e.g., a Dense layer) and applies it at every time step of its input seq. It reshapes the input from [batch size, time steps, input dim] to [batch size*time steps, input dim]. Finally, it reshapes the outputs back to seq. </p>
<pre class=" language-python"><code class="language-python">model <span class="token operator">=</span> Sequentail<span class="token punctuation">(</span><span class="token punctuation">[</span>
    SimpleRNN<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span> return_sequences<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> input_shape<span class="token operator">=</span><span class="token punctuation">[</span>None<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    SimpleRNN<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span> return_sequences<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
    TimeDistributed<span class="token punctuation">(</span>Dense<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre>
<p>All outputs are needed during training, but only the output at the last time step is useful for predictions and evaluation. We need a custom metric for eval. </p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">last_step_mse</span><span class="token punctuation">(</span>ytrue<span class="token punctuation">,</span> ypred<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> keras<span class="token punctuation">.</span>metrics<span class="token punctuation">.</span>mean_squred_error<span class="token punctuation">(</span>ytrue<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> ypred<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

optm <span class="token operator">=</span> Adam<span class="token punctuation">(</span>lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>loss<span class="token operator">=</span><span class="token string">"mse"</span><span class="token punctuation">,</span> optimizer<span class="token operator">=</span>optm<span class="token punctuation">,</span> metrics<span class="token operator">=</span><span class="token punctuation">[</span>last_step_mse<span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre>
<p>When forecasting time series, it is often useful to have some error bars along with predictions. An efficient tech is MC Dropout. </p>
<h1 id="Long-Seq"><a href="#Long-Seq" class="headerlink" title="Long Seq"></a>Long Seq</h1><h3 id="Fighting-Unstable-Gradients"><a href="#Fighting-Unstable-Gradients" class="headerlink" title="Fighting Unstable Gradients"></a>Fighting Unstable Gradients</h3><p>If we notice that training is unstable, we may want to monitor the size of the gradients (using TensorBoard) and perhaps use Gradient Clipping. </p>
<p>Batch Normalization cannot be used as efficiently with RNNs as with deep feedforward nets. It is slightly better when applied between recurrent layers, but not within recurrent layers (horizontally).</p>
<p>Layer Normalization works better. It normalizes across the feature dimension. It can compute the required stat on the fly at each time step independently for each instance. It behaves the same during training and testing.  </p>
<p>We can implement Layer Normalization within a simple mem cell. </p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">LNRNNCell</span><span class="token punctuation">(</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Layer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> units<span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"tanh"</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>state_size <span class="token operator">=</span> units
        self<span class="token punctuation">.</span>output_size <span class="token operator">=</span> units
        self<span class="token punctuation">.</span>simple_rnn_cell <span class="token operator">=</span> SimpleRNNCell<span class="token punctuation">(</span>units<span class="token punctuation">,</span> activation<span class="token operator">=</span>None<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>layer_norm <span class="token operator">=</span> keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>LayerNormalization<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>activation <span class="token operator">=</span> keras<span class="token punctuation">.</span>activations<span class="token punctuation">.</span>get<span class="token punctuation">(</span>activation<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">call</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs<span class="token punctuation">,</span> states<span class="token punctuation">)</span><span class="token punctuation">:</span>
        outputs<span class="token punctuation">,</span> new_states <span class="token operator">=</span> self<span class="token punctuation">.</span>simple_rnn_cell<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> states<span class="token punctuation">)</span>
        norm_outputs <span class="token operator">=</span> self<span class="token punctuation">.</span>activation<span class="token punctuation">(</span>self<span class="token punctuation">.</span>layer_norm<span class="token punctuation">(</span>outputs<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> norm_outputs<span class="token punctuation">,</span> <span class="token punctuation">[</span>norm_outputs<span class="token punctuation">]</span></code></pre>
<p>We create a <code>SimpleRNNCell</code> with no activation function, because we want to perform LN after the linear operation but before the activation function. The outputs for SimpleRNNCell are just equal to the hidden states. To use this custom cell, all we need is create a keras.layers.RNN layer. </p>
<pre class=" language-python"><code class="language-python">model <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>
    RNN<span class="token punctuation">(</span>LNSimpleRNNCell<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">,</span> return_sequences<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> input_shape<span class="token operator">=</span><span class="token punctuation">[</span>None<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    RNN<span class="token punctuation">(</span>LNSimpleRNNCell<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">,</span> return_sequences<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    TimeDistributed<span class="token punctuation">(</span>Dense<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre>
<p>Similarly, we can create a custom cell to apply dropout between each time step. But all recurrent layers except for keras.layers.RNN layer provided by Keras have a dropout hyperparameter and a recurrent_dropout hyperparam: the former defines the dropout rate to apply to the inputs at each time step, and the latter defines the dropout rate for the hidden states. </p>
<h3 id="Tackle-Short-Term-Mem"><a href="#Tackle-Short-Term-Mem" class="headerlink" title="Tackle Short Term Mem"></a>Tackle Short Term Mem</h3><h4 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h4><pre class=" language-python"><code class="language-python">model <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>
    LSTM<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span> return_sequences<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> input_shape<span class="token operator">=</span><span class="token punctuation">[</span>None<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    LSTM<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span> return_sequences<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    TimeDistributed<span class="token punctuation">(</span>Dense<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre>
<p>Alternatively, we can use the general-purpose keras.layers.RNN layer. </p>
<pre class=" language-python"><code class="language-python">model <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>
    RNN<span class="token punctuation">(</span>LSTM<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">,</span> return_sequences<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> input_shape<span class="token operator">=</span><span class="token punctuation">[</span>None<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    RNN<span class="token punctuation">(</span>LSTM<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">,</span> return_sequences<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    TimeDistributed<span class="token punctuation">(</span>Dense<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre>
<p>The LSTM uses an optimized implementation when running on a GPU. So, in general it is preferable to use it. </p>
<p>It has two states: $h_t$ and $c_t$, short-term state and long-term state respectively. </p>
<img src="1501.PNG" height="300" width="500">

<p>When long term states $c_{t-1}$ traverses the network, it first goes through a forget gate, dropping some mem, and then it adds some new mem via the addition operation. The result is  $c_t$, which is sent w/o further transformation. After the addition operation, the long-term state is copied and passed thru the tanh func, and then the result is filtered by the output gate, which produce short timer mem $h_t$. </p>
<p>Now let’s look at where new mem comes from and how gates work. </p>
<p>First, the current input vec $x_t$ and the previous short term state  $h_{t-1}$ are fed to four different fully connected layers. </p>
<ol>
<li>The main layer is the one that outputs $g_t$. It is the same as in any other basic cell. In LSTM, this layer’s output does not go straight out, but its most important parts are stored in the long term state. </li>
<li>The three other layers are gate controllers. They use logistic activation func, their outputs range from 0 to 1. They output 0s meaning close the gate, otherwise open the gate. The forget gate controls which parts of the long-term state should be erase. The input gate controls which parts of $g_t$ should be added to the long-term state. The output gate controls which parts of the long-term state should be read and output at this time step, both the $h_t$ and to $y_t$. </li>
</ol>
<h4 id="Peehole-connections"><a href="#Peehole-connections" class="headerlink" title="Peehole connections"></a>Peehole connections</h4><p>It may be a good idea to give LSTM a bit more context by letting them peek at the long-term state as well. Peehole connections is an extra connections. </p>
<p>In Keras, the LSTM layer does not support peepholes. The experimental tf.keras.experimental.PeepholeLSTMCell does. </p>
<h4 id="GRU"><a href="#GRU" class="headerlink" title="GRU"></a>GRU</h4><p>The Gated Recurrent Unit. </p>
<img src="1502.PNG" height="300" width="500">

<p>Simplified version of LSTM. </p>
<p>Both state vectors are merged into a single vector $h_t$. A single gate controller $z_t$ controls both the forget gate and input gate. If the gate controller outputs 1, the forget gate is open and input gate is closed. In other words, whenever a mem must be stored, the location where it will be stored is erased first. There is not output gate, but there is a new gate controller $r_t$ controlling which part of the previous state will be shown to the main layer $g_t$. </p>
<h4 id="1D-Conv-Layers"><a href="#1D-Conv-Layers" class="headerlink" title="1D Conv Layers"></a>1D Conv Layers</h4><p>The methods above try to learn long-term patterns. This tech tries to reduce input seq length. </p>
<p>A 1D conv layer slides several kernels across a seq, producing a 1D feature map per kernel. Each kernel will learn to detect a single very short seq pattern. The example below downsamples the input seq by a factor of 2 using a stride=2. The kernel size is larger than the stride, so all inputs will be used to compute the layer’s output. Note we must also crop off the first three time steps in the targets (kernel_size=4, the first output of the conv layer will be based on the input time steps 0 to 3). </p>
<pre class=" language-python"><code class="language-python">model <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>
    Conv1D<span class="token punctuation">(</span>filters<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span> kernal_size<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">"valid"</span><span class="token punctuation">,</span> input_shape<span class="token operator">=</span><span class="token punctuation">[</span>None<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    GRU<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span> return_sequences<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    GRU<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span> return_sequences<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    TimeDistributed<span class="token punctuation">(</span>Dense<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>loss<span class="token operator">=</span><span class="token string">"mse"</span><span class="token punctuation">,</span> optimizer<span class="token operator">=</span><span class="token string">"adam"</span><span class="token punctuation">,</span> metrics<span class="token operator">=</span><span class="token punctuation">[</span>last_time_step_mse<span class="token punctuation">]</span><span class="token punctuation">)</span>
hist <span class="token operator">=</span> model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>xtrian<span class="token punctuation">,</span> ytrain<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> epochs<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span> validation_data<span class="token operator">=</span><span class="token punctuation">(</span>xval<span class="token punctuation">,</span> yval<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre>
<h4 id="WaveNet"><a href="#WaveNet" class="headerlink" title="WaveNet"></a>WaveNet</h4><p>Stacked 1D conv layers, doubling the dilation rate at every layer. This way, the lower layers learn short term patterns, while the higher layers learn long term patterns. </p>
<p>In WaveNet paper, they stacked 10 conv layers with dilation rates of 1~512, then repeat 3 such blocks. </p>
<pre class=" language-python"><code class="language-python">model <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>InputLayer<span class="token punctuation">(</span>input_shape<span class="token operator">=</span><span class="token punctuation">[</span>None<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> rate <span class="token keyword">in</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token operator">*</span><span class="token number">2</span><span class="token punctuation">:</span>
    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Conv1D<span class="token punctuation">(</span>filters<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">"causal"</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"relu"</span><span class="token punctuation">,</span> dilation_rate<span class="token operator">=</span>rate<span class="token punctuation">)</span><span class="token punctuation">)</span>

model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Conv1D<span class="token punctuation">(</span>filters<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>loss<span class="token operator">=</span><span class="token string">"mse"</span><span class="token punctuation">,</span> optimizer<span class="token operator">=</span><span class="token string">"adam"</span><span class="token punctuation">,</span> metrics<span class="token operator">=</span><span class="token punctuation">[</span>last_step_mse<span class="token punctuation">]</span><span class="token punctuation">)</span>
hist <span class="token operator">=</span> model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>xtrain<span class="token punctuation">,</span> ytrain<span class="token punctuation">,</span> epochs<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span> validation_data<span class="token operator">=</span><span class="token punctuation">(</span>xval<span class="token punctuation">,</span> yval<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre>
<p>“causal” padding ensures that the conv layer does not peek into the future when making predictions (equivalent to padding the inputs with right amount of zeros on the left and using valid padding).  </p>

            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        Author:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Blog/about" rel="external nofollow noreferrer">csy99</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        Link:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="http://csy99.github.io/Blog/2020/08/16/hands-on-15-sequence/">http://csy99.github.io/Blog/2020/08/16/hands-on-15-sequence/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        Reprint policy:
                    </i>
                </span>
                <span class="reprint-info">
                    All articles in this blog are used except for special statements
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    reprint polocy. If reproduced, please indicate source
                    <a href="/Blog/about" target="_blank">csy99</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>Copied successfully, please follow the reprint policy of this article</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">more</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Blog/tags/DL/">
                                    <span class="chip bg-color">DL</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Blog/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,qq,wechat,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Blog/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <style>
    #reward {
        margin: 30px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.4rem;
        line-height: 38px;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 520px;
        height: 550px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 30px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

	// 调整tab距离
    #rewardModal .reward-tabs { 
        margin: 0 auto;
        width: 410px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }
	
	.reward-tabs .venmo-tab .active {
        color: #fff !important;
        background-color: #555555 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">Your recognition will motivate me!</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s4 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s4 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
						<li class="tab col s4 venmo-tab waves-effect waves-light"><a href="#venmo">Venmo</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/Blog/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/Blog/medias/reward/wechat.jpg" class="reward-img" alt="微信打赏二维码">
                    </div>
					<div id="venmo">
                        <img src="/Blog/medias/reward/venmo.jpg" class="reward-img" alt="Venmo QR code">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    
        <link rel="stylesheet" href="/Blog/libs/gitalk/gitalk.css">
<link rel="stylesheet" href="/Blog/css/my-gitalk.css">

<div class="card gitalk-card" data-aos="fade-up">
    <div class="comment_headling" style="font-size: 20px; font-weight: 700; position: relative; padding-left: 20px; top: 15px; padding-bottom: 5px;">
        <i class="fas fa-comments fa-fw" aria-hidden="true"></i>
        <span>评论</span>
    </div>
    <div id="gitalk-container" class="card-content"></div>
</div>

<script src="/Blog/libs/gitalk/gitalk.min.js"></script>
<script>
    let gitalk = new Gitalk({
        clientID: 'aecfa0a3613bd862ed5f',
        clientSecret: '7bd4e6a082f93ffb388a540481f5be3c59151255',
        repo: 'Blog',
        owner: 'csy99',
        admin: "csy99",
        id: '2020-08-16T21-30-54',
        distractionFreeMode: false  // Facebook-like distraction free mode
    });

    gitalk.render('gitalk-container');
</script>

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;Previous</div>
            <div class="card">
                <a href="/Blog/2020/08/16/sleep-wait-yield/">
                    <div class="card-image">
                        
                        
                        <img src="/Blog/medias/featureimages/17.jpg" class="responsive-img" alt="sleep wait yield">
                        
                        <span class="card-title">sleep wait yield</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            sleep、wait和yield都是暂停线程的方法。
定义的类sleep()和yield()方法是定义在Thread类中，而wait()方法是定义在Object类中。
sleep在Java中Sleep方法有两个，一个只有一个毫秒参数，另一个
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2020-08-16
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Blog/categories/Java/" class="post-category">
                                    Java
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Blog/tags/thread/">
                        <span class="chip bg-color">thread</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                Next&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Blog/2020/08/16/hands-on-03-classification/">
                    <div class="card-image">
                        
                        
                        <img src="/Blog/medias/featureimages/15.jpg" class="responsive-img" alt="hands on: 03 classification">
                        
                        <span class="card-title">hands on: 03 classification</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2020-08-16
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Blog/categories/Deep-Learning/" class="post-category">
                                    Deep Learning
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Blog/tags/DL/">
                        <span class="chip bg-color">DL</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Blog/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="/Blog/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Blog/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Blog/libs/codeBlock/codeShrink.js"></script>


<!-- 代码块折行 -->

<style type="text/css">
code[class*="language-"], pre[class*="language-"] { white-space: pre !important; }
</style>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;TOC</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Blog/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('3'),
            headingSelector: 'h1, h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h1, h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>


<script src="https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
    MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$', '$'], ['\(', '\)']]}
    });
</script>



    <footer class="page-footer bg-color">
    
    <div class="container row center-align" style="margin-bottom: 0px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            <span id="year">2020</span>
            <a href="/Blog/about" target="_blank">csy99</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            <br>
            
            
            
            
            
            
            <span id="busuanzi_container_site_pv">
                |&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv"
                    class="white-color"></span>&nbsp;次
            </span>
            
            
            <span id="busuanzi_container_site_uv">
                |&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv"
                    class="white-color"></span>&nbsp;人
            </span>
            
            <br>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/csy99" class="tooltipped" target="_blank" data-tooltip="我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:1264629690@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=1264629690" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 1264629690" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>







</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;Search</span>
            <input type="search" id="searchInput" name="s" placeholder="Please enter a search keyword"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script src="/Blog/js/search.js"></script>
<script type="text/javascript">
$(function () {
    searchFunc("/Blog/search.xml", 'searchInput', 'searchResult');
});
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Blog/libs/materialize/materialize.min.js"></script>
    <script src="/Blog/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Blog/libs/aos/aos.js"></script>
    <script src="/Blog/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Blog/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Blog/js/matery.js"></script>

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Blog/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Blog/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    

    

    

    
    <script src="/Blog/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
