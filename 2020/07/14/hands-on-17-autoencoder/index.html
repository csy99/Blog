<!DOCTYPE HTML>
<html lang="en">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="hands on: 17 autoencoder, Tech Blog">
    <meta name="description" content="">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>hands on: 17 autoencoder | Tech Blog</title>
    <link rel="icon" type="image/jpeg" href="/Blog/medias/teemo.jpeg">

    <link rel="stylesheet" type="text/css" href="/Blog/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="/Blog/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/Blog/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/Blog/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/Blog/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/Blog/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/Blog/css/my.css">

    <script src="/Blog/libs/jquery/jquery.min.js"></script>

<meta name="generator" content="Hexo 5.0.2"><link rel="stylesheet" href="/Blog/css/prism-tomorrow.css" type="text/css"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Blog/" class="waves-effect waves-light">
                    
                    <img src="/Blog/medias/teemo.jpeg" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Tech Blog</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Blog/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>Index</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Blog/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>Tags</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Blog/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>Categories</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Blog/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>Archives</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Blog/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>About</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Blog/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>Contact</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Blog/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>Friends</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="Search" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Blog/medias/teemo.jpeg" class="logo-img circle responsive-img">
        
        <div class="logo-name">Tech Blog</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Blog/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			Index
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Blog/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			Tags
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Blog/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			Categories
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Blog/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			Archives
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Blog/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			About
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Blog/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			Contact
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Blog/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			Friends
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/csy99/Blog" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork My Blog
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/csy99/Blog" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork My Blog" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/Blog/medias/featureimages/12.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">hands on: 17 autoencoder</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="/Blog/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        margin: 35px 0 15px 0;
        padding-left: 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        height: calc(100vh - 250px);
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;

        position: absolute;
        right: 23.5vw;
        display: block;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Blog/tags/DL/">
                                <span class="chip bg-color">DL</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Blog/categories/Deep-Learning/" class="post-category">
                                Deep Learning
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>Publish Date:&nbsp;&nbsp;
                    2020-07-14
                </div>
                

                

                

                

                
            </div>
        </div>
        <hr class="clearfix">
        <div class="card-content article-card-content">
            <div id="articleContent">
                <h1 id="Performing-PCA-with-an-Undercomplete-Linear-Autoencoder"><a href="#Performing-PCA-with-an-Undercomplete-Linear-Autoencoder" class="headerlink" title="Performing PCA with an Undercomplete Linear Autoencoder"></a>Performing PCA with an Undercomplete Linear Autoencoder</h1><p>The following code builds a simple linear autoencoder to perform PCA on a 3D dataset projecting it to 2D. </p>
<pre class=" language-python"><code class="language-python">encoder <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>Dense<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> input_shape<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
decoder <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>Dense<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> input_shape<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
autoencoder <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>encoder<span class="token punctuation">,</span> decoder<span class="token punctuation">]</span><span class="token punctuation">)</span>
autoencoder<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>loss<span class="token operator">=</span><span class="token string">"mse"</span><span class="token punctuation">,</span> optimizer<span class="token operator">=</span>SGD<span class="token punctuation">(</span>lr<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre>
<p>The autoencoder’s number of outputs is equal to the inputs. To perform simple PCA, we do not use any activation function. </p>
<pre class=" language-python"><code class="language-python">hist <span class="token operator">=</span> autoencder<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>xtrain<span class="token punctuation">,</span> xtrain<span class="token punctuation">,</span> epochs<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">)</span>
codings <span class="token operator">=</span> encoder<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>xtrain<span class="token punctuation">)</span></code></pre>
<h1 id="Stacked-Autoencoders"><a href="#Stacked-Autoencoders" class="headerlink" title="Stacked Autoencoders"></a>Stacked Autoencoders</h1><p>Stacked/deep autoencoders: have multiple hidden layers</p>
<p>The following one is built for MNIST. </p>
<pre class=" language-python"><code class="language-python">encoder <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>
    Flatten<span class="token punctuation">(</span>input_shape<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Dense<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"selu"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Dense<span class="token punctuation">(</span><span class="token number">30</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"selu"</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>
decoder <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>
    Dense<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"selu"</span><span class="token punctuation">,</span> input_shape<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">30</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Dense<span class="token punctuation">(</span><span class="token number">28</span><span class="token operator">*</span><span class="token number">28</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"sigmoid"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Reshape<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>
ae <span class="token operator">=</span> Sequantial<span class="token punctuation">(</span><span class="token punctuation">[</span>encoder<span class="token punctuation">,</span> decoder<span class="token punctuation">]</span><span class="token punctuation">)</span>
ae<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>loss<span class="token operator">=</span><span class="token string">"binary_crossentropy"</span><span class="token punctuation">,</span> 
          optimizer<span class="token operator">=</span>SGD<span class="token punctuation">(</span>lr<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
hist <span class="token operator">=</span> ae<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>xtrain<span class="token punctuation">,</span> xtrain<span class="token punctuation">,</span> epochs<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> 
             validation_data<span class="token operator">=</span><span class="token punctuation">[</span>xvalid<span class="token punctuation">,</span> xvalid<span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre>
<p>When compiling the stacked autoencoder, we use binary cross-entropy loss rather than MSE. We are treating the reconstruction task as a multilabel binary classification problem. This makes the model converges faster. </p>
<h3 id="Visualize-the-Reconstructions"><a href="#Visualize-the-Reconstructions" class="headerlink" title="Visualize the Reconstructions"></a>Visualize the Reconstructions</h3><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">plot_image</span><span class="token punctuation">(</span>image<span class="token punctuation">)</span><span class="token punctuation">:</span>
    plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>image<span class="token punctuation">,</span> cmap<span class="token operator">=</span><span class="token string">"binary"</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token string">"off"</span><span class="token punctuation">)</span>
<span class="token keyword">def</span> <span class="token function">show_reconstructions</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> n_images<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    reconstr <span class="token operator">=</span> model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>xval<span class="token punctuation">[</span><span class="token punctuation">:</span>n_images<span class="token punctuation">]</span><span class="token punctuation">)</span>
    fig <span class="token operator">=</span> plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span>n_images<span class="token operator">*</span><span class="token number">1.5</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> image_idx <span class="token keyword">in</span> range<span class="token punctuation">(</span>n_images<span class="token punctuation">)</span><span class="token punctuation">:</span>
        plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> n_images<span class="token punctuation">,</span> <span class="token number">1</span><span class="token operator">+</span>image_idx<span class="token punctuation">)</span>
        plot_image<span class="token punctuation">(</span>xval<span class="token punctuation">[</span>image_idx<span class="token punctuation">]</span><span class="token punctuation">)</span>
        plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> n_images<span class="token punctuation">,</span> <span class="token number">1</span><span class="token operator">+</span>n_images<span class="token operator">+</span>image_idx<span class="token punctuation">)</span>
        plot_image<span class="token punctuation">(</span>reconstr<span class="token punctuation">[</span>image_idx<span class="token punctuation">]</span><span class="token punctuation">)</span>
show_reconstructions<span class="token punctuation">(</span>ae<span class="token punctuation">)</span></code></pre>
<p>For visualization, autoencoder does not give great results, but it can handle large datasets. So one strategy is to use an autoencoder to reduce the dimensionality down to a reasonable level, then use another dimensionality reduction algorithm for visualization. </p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>manifold <span class="token keyword">import</span> TSNE
xval_compressed <span class="token operator">=</span> encoder<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>xval<span class="token punctuation">)</span>
tsne <span class="token operator">=</span> TSNE<span class="token punctuation">(</span><span class="token punctuation">)</span>
xval_2d <span class="token operator">=</span> tsne<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>xval_compressed<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>xval_2d<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> xval_2d<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span>yval<span class="token punctuation">,</span> s<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> 
           cmap<span class="token operator">=</span><span class="token string">"tab10"</span><span class="token punctuation">)</span></code></pre>
<h3 id="Unsupervised-Pretraining-using-AE"><a href="#Unsupervised-Pretraining-using-AE" class="headerlink" title="Unsupervised Pretraining using AE"></a>Unsupervised Pretraining using AE</h3><img src="1701.PNG" alt="pretrain">

<p>Having plenty of unlabeled data and a little labeled data. Use autoencoder to pretrain and copy the weights to new model which can be used to train labeled data. </p>
<h3 id="Tying-Weights"><a href="#Tying-Weights" class="headerlink" title="Tying Weights"></a>Tying Weights</h3><p>When an autoencoder is symmetrical, a common tech is to tie the weights of the decoder layers to the weights of the encoder. This halves the number of weights in the model, speeding up training and limiting the risk of overfitting. </p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">DenseTranspose</span><span class="token punctuation">(</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Layer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> dense<span class="token punctuation">,</span> activation<span class="token operator">=</span>None<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>dense <span class="token operator">=</span> dense
        self<span class="token punctuation">.</span>activation <span class="token operator">=</span> keras<span class="token punctuation">.</span>activations<span class="token punctuation">.</span>get<span class="token punctuation">(</span>activation<span class="token punctuation">)</span>
        super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">build</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch_input_shape<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>biases <span class="token operator">=</span> self<span class="token punctuation">.</span>add_weight<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">"bias"</span><span class="token punctuation">,</span> initializer<span class="token operator">=</span><span class="token string">"zeros"</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>input_shape<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>build<span class="token punctuation">(</span>batch_input_shape<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">call</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        z <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> self<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>weights<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> transpose_b<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>activation<span class="token punctuation">(</span>z <span class="token operator">+</span> self<span class="token punctuation">.</span>biases<span class="token punctuation">)</span></code></pre>
<p>Next, we can build a new stacked AE. </p>
<pre class=" language-python"><code class="language-python">dense_1 <span class="token operator">=</span> Dense<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"selu"</span><span class="token punctuation">)</span>
dense_2 <span class="token operator">=</span> Dense<span class="token punctuation">(</span><span class="token number">30</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"selu"</span><span class="token punctuation">)</span>
tied_encoder <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>
    Flatten<span class="token punctuation">(</span>input_shape<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    dense_1<span class="token punctuation">,</span> 
    dense_2
<span class="token punctuation">]</span><span class="token punctuation">)</span>
tied_decoder <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>
    DenseTranspose<span class="token punctuation">(</span>dense_2<span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"selu"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    DenseTranspose<span class="token punctuation">(</span>dense_1<span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"sigmoid"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Reshape<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>
tied_ae <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>tied_encoder<span class="token punctuation">,</span> tied_decoder<span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre>
<h3 id="Training-One-AE-at-a-time"><a href="#Training-One-AE-at-a-time" class="headerlink" title="Training One AE at a time"></a>Training One AE at a time</h3><p>Rather than training the whole stacked autoencoder in one go, we can train one shallow autoencoder at a time and then stack all of them. </p>
<p>During the first phase of training, the first AE learns to reconstruct the inputs. We encode the whole training set using this AE to get a new compressed training set. During, second phase, we then train a second autoencoder on this new set. Finally, we build a big sandwich using all these AE. </p>
<h3 id="Convolutional-AE"><a href="#Convolutional-AE" class="headerlink" title="Convolutional AE"></a>Convolutional AE</h3><p>The encoder is a regular CNN composed of convolutional layers and pooling layers. It typically reduces the spatial dimensionality of the inputs while increasing the depth. The decoder must do the reverse. </p>
<p>Below is a example for Fashion MNIST. </p>
<pre class=" language-python"><code class="language-python">conv_encoder <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>
    Reshape<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> input_shape<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Conv2D<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">"same"</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"selu"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    MaxPool2D<span class="token punctuation">(</span>pool_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Conv2D<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">"same"</span><span class="token punctuation">,</span> actvation<span class="token operator">=</span><span class="token string">"selu"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    MaxPool2D<span class="token punctuation">(</span>pool_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Conv2D<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">"same"</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"selu"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    MaxPool2D<span class="token punctuation">(</span>pool_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>
conv_decoder <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>
    Conv2DTranspose<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">"valid"</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"selu"</span><span class="token punctuation">,</span> input_shape<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Conv2DTranspose<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">"same"</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"selu"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Conv2DTranspose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">"same"</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"sigmoid"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Reshape<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>
conv_ae <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>conv_encoder<span class="token punctuation">,</span> conv_decoder<span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre>
<h3 id="Recurrent-AE"><a href="#Recurrent-AE" class="headerlink" title="Recurrent AE"></a>Recurrent AE</h3><p>Build an autoencoder for sequences. The encoder is a sequence-to-vector RNN which compresses the input sequence down to a single vector. The decoder is a vector-to-sequence RNN that does the reverse. </p>
<pre class=" language-python"><code class="language-python">recurrent_encoder <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>
    LSTM<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span> return_sequences<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> input_shape<span class="token operator">=</span><span class="token punctuation">[</span>None<span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
    LSTM<span class="token punctuation">(</span><span class="token number">30</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>
recurrent_decoder <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>
    RepeatVector<span class="token punctuation">(</span><span class="token number">28</span><span class="token punctuation">,</span> input_shape<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">30</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    LSTM<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span> return_sequences<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    TimeDistributed<span class="token punctuation">(</span>Dense<span class="token punctuation">(</span><span class="token number">28</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"sigmoid"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>
recurrent_ae <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>recurrent_encoder<span class="token punctuation">,</span> recurrent_decoder<span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre>
<p>The recurrent autoencoder can process sequences of any length. We use a RepeatVector layer as the first layer of the decoder, to ensure that its input vector gets fed to the decoder at each time step. </p>
<h3 id="Denoising-AE"><a href="#Denoising-AE" class="headerlink" title="Denoising AE"></a>Denoising AE</h3><p>Another way to force the AE to learn useful features is to add noise to its inputs, training it to recover the original, noise-free inputs. The implementation is a regular stacked AE with an additional Dropout layer applied to the encoder’s inputs. </p>
<pre class=" language-python"><code class="language-python">dropout_encoder <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>
    Flatten<span class="token punctuation">(</span>input_shape<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Dropout<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Dense<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"selu"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Dense<span class="token punctuation">(</span><span class="token number">30</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"selu"</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>
dropout_decoder <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>
    Dense<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"selu"</span><span class="token punctuation">,</span> input_shape<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">30</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Dense<span class="token punctuation">(</span><span class="token number">28</span><span class="token operator">*</span><span class="token number">28</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"sigmoid"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Reshape<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>
dropout_ae <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>dropout_encoder<span class="token punctuation">,</span> dropout_decoder<span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre>
<h3 id="Sparse-AE"><a href="#Sparse-AE" class="headerlink" title="Sparse AE"></a>Sparse AE</h3><p>Sparsity often leads to good feature extraction. We can force the AE to represent each input as a combination of a small number of activations. As a result, each neuron in the coding layer typically ends up representing a useful feature. </p>
<pre class=" language-python"><code class="language-python">sparse_encoder <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>
    Flatten<span class="token punctuation">(</span>input_shape<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Dense<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"selu"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Dense<span class="token punctuation">(</span><span class="token number">300</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"sigmoid"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    ActivityRegularization<span class="token punctuation">(</span>l1<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>
sparse_decoder <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>
    Dense<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"selu"</span><span class="token punctuation">,</span> input_shape<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">300</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Dense<span class="token punctuation">(</span><span class="token number">28</span><span class="token operator">*</span><span class="token number">28</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"sigmoid"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Reshape<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>
sparse_ae <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>sparse_encoder<span class="token punctuation">,</span> sparse_decoder<span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre>
<p>The ActivityRegularization layer just return its inputs, but adds a training loss equal to the sum of absolute values of its input (only has an effect during training). Equivalently, we can remove this layer and set <strong>activity_regularizer=keras.regularizers.l1(1e-3)</strong> in the previous layer. </p>
<p>Another approach is to measure the actual sparsity of the coding layer at each training iteration, and penalize the model when the measured sparsity differs from a target sparsity. We can simply adding the squared error to the cost function, but it is better to use Kullback-Leibler divergence. We want to measure the divergence between the target probability p that a neuron in the coding layer will activate and the actual probability q (i.e., the mean activation over the training batch).</p>
<p>$D_{KL}(p||q) = p*log\frac{p}{q} + (1-p)*log\frac{1-p}{1-q}$</p>
<p>Once we have computed the sparsity loss for each neuron in the coding layer, we sum up these losses and add the result to the cost function. </p>
<pre class=" language-python"><code class="language-python">K <span class="token operator">=</span> keras<span class="token punctuation">.</span>backend
kl_diver <span class="token operator">=</span> keras<span class="token punctuation">.</span>losses<span class="token punctuation">.</span>kullback_leibler_divergence
<span class="token keyword">class</span> <span class="token class-name">KLDiverRegularizer</span><span class="token punctuation">(</span>keras<span class="token punctuation">.</span>regularizers<span class="token punctuation">.</span>Regularizer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> weight<span class="token punctuation">,</span> target<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>weight <span class="token operator">=</span> weight
        self<span class="token punctuation">.</span>target <span class="token operator">=</span> target
    <span class="token keyword">def</span> <span class="token function">__call__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        mean_activities <span class="token operator">=</span> K<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>weight<span class="token operator">*</span><span class="token punctuation">(</span>kl_diver<span class="token punctuation">(</span>self<span class="token punctuation">.</span>target<span class="token punctuation">,</span> mean_activities<span class="token punctuation">)</span><span class="token operator">+</span>kl_diver<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token operator">-</span>selftarget<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token operator">-</span>mean_activities<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre>
<p>Now we can build the sparse autoencoder. </p>
<pre class=" language-python"><code class="language-python">kld_reg <span class="token operator">=</span> KLDiverRegularizer<span class="token punctuation">(</span>weight<span class="token operator">=</span><span class="token number">0.05</span><span class="token punctuation">,</span> target<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span>
sparse_kl_encoder <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>
    Flatten<span class="token punctuation">(</span>input_shape<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Dense<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"selu"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Dense<span class="token punctuation">(</span><span class="token number">300</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"sigmoid"</span><span class="token punctuation">,</span> 
         activity_regularizer<span class="token operator">=</span>kld_reg<span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>
sparse_kl_decoder <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>
    Dense<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"selu"</span><span class="token punctuation">,</span> input_shape<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">300</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Dense<span class="token punctuation">(</span><span class="token number">28</span><span class="token operator">*</span><span class="token number">28</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"sigmoid"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Reshape<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>
sparse_kl_ae <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>sparse_kl_encoder<span class="token punctuation">,</span> sparse_kl_decoder<span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre>
<h3 id="Variational-Autoencoders"><a href="#Variational-Autoencoders" class="headerlink" title="Variational Autoencoders"></a>Variational Autoencoders</h3><p>Difference:</p>
<ol>
<li>probabilistic autoencoders (outputs are partly determined by chance, even after training)</li>
<li>generative autoencoders (generate new instances that look like they were sampled from the training set)</li>
</ol>
<p>Instead of directly producing a coding for a given input, the encoder produces a mean coding and a std. The actual coding is then sampled randomly from a Gaussian distribution. </p>
<p>Cost function:</p>
<ol>
<li>reconstruction loss (push the AE to reproduce its inputs)</li>
<li>latent loss (push the AE to have codings that look as though they were sampled from a simple Gaussian distribution)</li>
</ol>
<p>Latent Loss: $L = -0.5\sum_{i=1}^K 1 + log(\sigma_i^2) - \sigma_i^2 - \mu_i^2$. </p>
<p>A common trick is to make the encoder output $\gamma = log(\sigma_i^2)$ instead of $\sigma$. It is more numerically stable and speeds up training. </p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Sampling</span><span class="token punctuation">(</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Layer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">call</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        mean<span class="token punctuation">,</span> log_var <span class="token operator">=</span> inputs
        <span class="token keyword">return</span> K<span class="token punctuation">.</span>random_normal<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>shape<span class="token punctuation">(</span>log_var<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">*</span>K<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>log_var<span class="token operator">/</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token operator">+</span>mean</code></pre>
<p>When we create the encoder, we need Functional API, since the model is not entirely sequential. </p>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># encoder</span>
coding_size <span class="token operator">=</span> <span class="token number">10</span>
inputs <span class="token operator">=</span> Input<span class="token punctuation">(</span>shape<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
z <span class="token operator">=</span> Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
z <span class="token operator">=</span> Dense<span class="token punctuation">(</span><span class="token number">150</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"selu"</span><span class="token punctuation">)</span><span class="token punctuation">(</span>z<span class="token punctuation">)</span>
z <span class="token operator">=</span> Dense<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"selu"</span><span class="token punctuation">)</span><span class="token punctuation">(</span>z<span class="token punctuation">)</span>
codings_mean <span class="token operator">=</span> Dense<span class="token punctuation">(</span>codings_size<span class="token punctuation">)</span><span class="token punctuation">(</span>z<span class="token punctuation">)</span>
codings_log_var <span class="token operator">=</span> Dense<span class="token punctuation">(</span>codings_size<span class="token punctuation">)</span><span class="token punctuation">(</span>z<span class="token punctuation">)</span>
codings <span class="token operator">=</span> Sampling<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">(</span><span class="token punctuation">[</span>codings_mean<span class="token punctuation">,</span> codings_log_var<span class="token punctuation">]</span><span class="token punctuation">)</span>
variational_encoder <span class="token operator">=</span> keras<span class="token punctuation">.</span>Model<span class="token punctuation">(</span>inputs<span class="token operator">=</span><span class="token punctuation">[</span>inputs<span class="token punctuation">]</span><span class="token punctuation">,</span> outputs<span class="token operator">=</span><span class="token punctuation">[</span>codings_mean<span class="token punctuation">,</span> codings_log_var<span class="token punctuation">,</span> codings<span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># decoder</span>
decoder_inputs <span class="token operator">=</span> Input<span class="token punctuation">(</span>shape<span class="token operator">=</span><span class="token punctuation">[</span>coding_size<span class="token punctuation">]</span><span class="token punctuation">)</span>
x <span class="token operator">=</span> Dense<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"selu"</span><span class="token punctuation">)</span><span class="token punctuation">(</span>decoder_inputs<span class="token punctuation">)</span>
x <span class="token operator">=</span> Dense<span class="token punctuation">(</span><span class="token number">150</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"selu"</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
x <span class="token operator">=</span> Dense<span class="token punctuation">(</span><span class="token number">28</span><span class="token operator">*</span><span class="token number">28</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"sigmoid"</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
outputs <span class="token operator">=</span> Reshape<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
variational_decoder <span class="token operator">=</span> keras<span class="token punctuation">.</span>Model<span class="token punctuation">(</span>inputs<span class="token operator">=</span><span class="token punctuation">[</span>decoder_inputs<span class="token punctuation">]</span><span class="token punctuation">,</span> outputs<span class="token operator">=</span><span class="token punctuation">[</span>outputs<span class="token punctuation">]</span><span class="token punctuation">)</span>

_<span class="token punctuation">,</span> _<span class="token punctuation">,</span> codings <span class="token operator">=</span> variational_encoder<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
reconstructions <span class="token operator">=</span> variational_decoder<span class="token punctuation">(</span>codings<span class="token punctuation">)</span>
variational_ae <span class="token operator">=</span> keras<span class="token punctuation">.</span>Model<span class="token punctuation">(</span>inputs<span class="token operator">=</span><span class="token punctuation">[</span>inputs<span class="token punctuation">]</span><span class="token punctuation">,</span> outputs<span class="token operator">=</span><span class="token punctuation">[</span>reconstructions<span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre>
<p>Lastly, we must add the latent loss and the reconstruction loss. </p>
<pre class=" language-python"><code class="language-python">latent_loss <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">0.5</span><span class="token operator">*</span>K<span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">+</span>codings_log_var<span class="token operator">-</span>K<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>codings_log_var<span class="token punctuation">)</span><span class="token operator">-</span>K<span class="token punctuation">.</span>square<span class="token punctuation">(</span>codings_mean<span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
variational_ae<span class="token punctuation">.</span>add_loss<span class="token punctuation">(</span>K<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>latent_loss<span class="token punctuation">)</span><span class="token operator">/</span><span class="token number">784</span><span class="token punctuation">.</span><span class="token punctuation">)</span>
variational_ae<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>loss<span class="token operator">=</span><span class="token string">"binary_crossentropy"</span><span class="token punctuation">,</span> optimizer<span class="token operator">=</span><span class="token string">"rmsprop"</span><span class="token punctuation">)</span>
hist <span class="token operator">=</span> variational_ae<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>xtrain<span class="token punctuation">,</span> xtrain<span class="token punctuation">,</span> validation_data<span class="token operator">=</span><span class="token punctuation">[</span>xval<span class="token punctuation">,</span> xval<span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre>
<p>We can generate images that look like fashion items by sampling random codings from a Gaussian distribution and decode them. </p>
<pre class=" language-python"><code class="language-python">codings <span class="token operator">=</span> tf<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span>shape<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">12</span><span class="token punctuation">,</span> codings_size<span class="token punctuation">]</span><span class="token punctuation">)</span>
images <span class="token operator">=</span> variational_decoder<span class="token punctuation">(</span>codings<span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre>
<p>Variational AE make it possible to perform semantic interpolation. </p>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># organized in a 3*4 grid and then resize to 5*7</span>
codings_grid <span class="token operator">=</span> tf<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>codings<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span>codings_size<span class="token punctuation">]</span><span class="token punctuation">)</span>
larger_grid <span class="token operator">=</span> tf<span class="token punctuation">.</span>image<span class="token punctuation">.</span>resize<span class="token punctuation">(</span>codings_grid<span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
interpolated_codings <span class="token operator">=</span> tf<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>larger_grid<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> codings_size<span class="token punctuation">]</span><span class="token punctuation">)</span>
images <span class="token operator">=</span> variational_decoder<span class="token punctuation">(</span>interpolated_codings<span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre>
<h1 id="Generative-Adversarial-Networks"><a href="#Generative-Adversarial-Networks" class="headerlink" title="Generative Adversarial Networks"></a>Generative Adversarial Networks</h1><p>Make NN compete against each other in the hope that this will push them to excel. </p>
<p>Generator: takes a random distribution as input and outputs some data (typically an image). It tries to produce images that look real enough to trick the discriminator. </p>
<p>Discriminator: takes either a fake image from the generator or a real image from the training set as input, and must guess whether the input image is fake or real. </p>
<p>Training iteration:</p>
<ol>
<li>train the discriminator. A batch of real images is sampled from the training set and is completed with an equal number of fake images produced by the generator. The loss is binary cross-entropy. BP only optimizes the weights of the discriminator during this phase.</li>
<li>train the generator. The generator produce another batch of fake images, and set all labels to 1, which means we want the generator to produce images that the discriminator will wrongly believe to be real. BP only optimizes the weights of the generator during this phase. </li>
</ol>
<p>The generator never actually sees any real images, and it only gets the gradients flowing back through the discriminator. However, the better the discriminator gets, the more info about the real images is contained in these secondhand gradients. </p>
<pre class=" language-python"><code class="language-python">coding_size <span class="token operator">=</span> <span class="token number">30</span>
generator <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>
    Dense<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"selu"</span><span class="token punctuation">,</span> input_shape<span class="token operator">=</span><span class="token punctuation">[</span>coding_size<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Dense<span class="token punctuation">(</span><span class="token number">150</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"selu"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Dense<span class="token punctuation">(</span><span class="token number">28</span><span class="token operator">*</span><span class="token number">28</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"sigmoid"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Reshape<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>
discriminator <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>
    Flatten<span class="token punctuation">(</span>input_shape<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Dense<span class="token punctuation">(</span><span class="token number">150</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"selu"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Dense<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"selu"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Dense<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"sigmoid"</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>
gan <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>generator<span class="token punctuation">,</span> discriminator<span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre>
<p>We do not need to compile generator. Besides, the discriminator should not be trained during the second phase. </p>
<pre class=" language-python"><code class="language-python">discriminator<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>loss<span class="token operator">=</span><span class="token string">"binary_crossentropy"</span><span class="token punctuation">,</span> optimizer<span class="token operator">=</span><span class="token string">"rmsprop"</span><span class="token punctuation">)</span>
discriminator<span class="token punctuation">.</span>trainable <span class="token operator">=</span> <span class="token boolean">False</span>
gan<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>loss<span class="token operator">=</span><span class="token string">"binary_crossentropy"</span><span class="token punctuation">,</span> optimizer<span class="token operator">=</span><span class="token string">"rmsprop"</span><span class="token punctuation">)</span></code></pre>
<p>We need to write a custom training loop. </p>
<pre class=" language-python"><code class="language-python">batch_size <span class="token operator">=</span> <span class="token number">32</span>
data <span class="token operator">=</span> tf<span class="token punctuation">.</span>data<span class="token punctuation">.</span>Dataset<span class="token punctuation">.</span>from_tensor_slices<span class="token punctuation">(</span>xtrain<span class="token punctuation">)</span><span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span>
data <span class="token operator">=</span> data<span class="token punctuation">.</span>batch<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> drop_remainder<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">.</span>prefetch<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">train_gan</span><span class="token punctuation">(</span>gan<span class="token punctuation">,</span> data<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> coding_size<span class="token punctuation">,</span> n_epochs<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    generator<span class="token punctuation">,</span> discriminator <span class="token operator">=</span> gan<span class="token punctuation">.</span>layers
    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span>n_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> X <span class="token keyword">in</span> data<span class="token punctuation">:</span>
            <span class="token comment" spellcheck="true"># phase 1</span>
            noise <span class="token operator">=</span> tf<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span>shape<span class="token operator">=</span><span class="token punctuation">[</span>batch_size<span class="token punctuation">,</span> coding_size<span class="token punctuation">]</span><span class="token punctuation">)</span>
            generated <span class="token operator">=</span> generator<span class="token punctuation">(</span>noise<span class="token punctuation">)</span>
            X_all <span class="token operator">=</span> tf<span class="token punctuation">.</span>concat<span class="token punctuation">(</span><span class="token punctuation">[</span>generated<span class="token punctuation">,</span> X<span class="token punctuation">]</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
            y1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token operator">*</span>batch_size <span class="token operator">+</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token operator">*</span>batch_size<span class="token punctuation">)</span>
            discriminator<span class="token punctuation">.</span>trainable <span class="token operator">=</span> <span class="token boolean">True</span>
            discriminator<span class="token punctuation">.</span>train_on_batch<span class="token punctuation">(</span>X_all<span class="token punctuation">,</span> y1<span class="token punctuation">)</span>
            <span class="token comment" spellcheck="true"># phase 2</span>
            noise <span class="token operator">=</span> tf<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span>shape<span class="token operator">=</span><span class="token punctuation">[</span>batch_size<span class="token punctuation">,</span> coding_size<span class="token punctuation">]</span><span class="token punctuation">)</span>
            y2 <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token operator">*</span>batch_size<span class="token punctuation">)</span>
            discriminator<span class="token punctuation">.</span>trainable <span class="token operator">=</span> <span class="token boolean">False</span>
            gan<span class="token punctuation">.</span>train_on_batch<span class="token punctuation">(</span>noise<span class="token punctuation">,</span> y2<span class="token punctuation">)</span>

train_gan<span class="token punctuation">(</span>gan<span class="token punctuation">,</span> data<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> coding_size<span class="token punctuation">)</span></code></pre>
<h3 id="Difficulties-of-Training-GANs"><a href="#Difficulties-of-Training-GANs" class="headerlink" title="Difficulties of Training GANs"></a>Difficulties of Training GANs</h3><p>GAN can only reach a single Nash equilibrium: the generator produces perfectly realistic images, and the discriminator is forced to guess. But nothing guarantees this equilibrium will be reached. </p>
<p>Sometimes, a GAN can forget what it learnt. The biggest difficulty is called mode collapse: when the generator’s outputs gradually become less diverse. The GAN may gradually cycle across a few classes, never really becoming very good at any of them. </p>
<p>Moreover, the parameters of gen and dis may end up becoming unstable. GAN is very sensitive to the hyperparams. </p>
<p>One solution is experience replay: storing the images produced by the generator at each iteration in a buffer, and training the discriminator using real images plus fake images drawn from this buffer rather than just fake images produced by the current generator. </p>
<p>Another solution is mini-batch discrimination: it measures how similar images are across the batch and provides this stat to the discriminator, so it can easily reject a whole batch of fake images that lack diversity. </p>
<h3 id="Deep-Conv-GANs"><a href="#Deep-Conv-GANs" class="headerlink" title="Deep Conv GANs"></a>Deep Conv GANs</h3><p>Principles:</p>
<ol>
<li>replace any pooling layers with strided convolutions in the discriminator and transposed convolutions in the generator</li>
<li>use batch normalization, except in generator’s output layer and the discriminator’s input layer</li>
<li>remove fully connected hidden layers for deeper architectures</li>
<li>use ReLU activation in the generator for all layers except the output layer, which should use tanh</li>
<li>use leaky ReLU activation in the discriminator for all layers</li>
</ol>
<pre class=" language-python"><code class="language-python">coding_size <span class="token operator">=</span> <span class="token number">100</span>
generator <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>
    Dense<span class="token punctuation">(</span><span class="token number">7</span><span class="token operator">*</span><span class="token number">7</span><span class="token operator">*</span><span class="token number">128</span><span class="token punctuation">,</span> input_shape<span class="token operator">=</span><span class="token punctuation">[</span>codings_size<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Reshape<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">128</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    BatchNormalization<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Conv2DTranspose<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">"same"</span><span class="token punctuation">,</span> activaton<span class="token operator">=</span><span class="token string">"selu"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    BatchNormalization<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Conv2DTranspose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">"same"</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"tanh"</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>
discriminator <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>
    Conv2D<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">"same"</span><span class="token punctuation">,</span> activation<span class="token operator">=</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> input_shape<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Dropout<span class="token punctuation">(</span><span class="token number">0.4</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Conv2D<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">"same"</span><span class="token punctuation">,</span> activation<span class="token operator">=</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Dropout<span class="token punctuation">(</span><span class="token number">0.4</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Dense<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"sigmoid"</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>
gan <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>generator<span class="token punctuation">,</span> discriminator<span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre>
<p>Before using this GAN, we need to rescale the training set, because the output for tanh is from -1 to 1. </p>
<pre class=" language-python"><code class="language-python">xtrain <span class="token operator">=</span> xtrain<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">*</span><span class="token number">2</span><span class="token punctuation">.</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">.</span></code></pre>
<h3 id="Progressive-Growing-of-GANs"><a href="#Progressive-Growing-of-GANs" class="headerlink" title="Progressive Growing of GANs"></a>Progressive Growing of GANs</h3><p>Generate small images at the beginning of training, then gradually adding conv layers to both the generator and the discriminator to produce larger images. </p>
<p>There are more techniques aiming at increasing the diversity of the outputs and making training more stable. </p>
<ol>
<li><p>minibatch standard deviation layer</p>
<p>added near the end of the discriminator. For each position in the inputs, it computes the std across all channels and instances in the batch.  These std are averaged across all points to get a single value. Finally, an extra feature map is added to each instance in the batch and filled with the computed value. If the generator produces images with little variety, then there will be a small standard deviation across feature maps in the discriminator. The dis will have easy access to this stat, making it less likely to be fooled by a generator that produces too little diveristy. </p>
<pre class=" language-python"><code class="language-python">S <span class="token operator">=</span> tf<span class="token punctuation">.</span>math<span class="token punctuation">.</span>reduce_std<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
v <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>S<span class="token punctuation">)</span>
tf<span class="token punctuation">.</span>concat<span class="token punctuation">(</span><span class="token punctuation">[</span>inputs<span class="token punctuation">,</span> tf<span class="token punctuation">.</span>fill<span class="token punctuation">(</span><span class="token punctuation">[</span>batch_size<span class="token punctuation">,</span> height<span class="token punctuation">,</span> width<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> v<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span></code></pre>
</li>
<li><p>equalized learning rate</p>
<p>Init all weights using a simple Gaussian distribution. However, the weights are scaled down at runtime by the same factor as in He init. This technique significantly improved the GAN’s performance when using RMSProp, Adam, or other adaptive gradient optimizers. Params that have a larger dynamic range will take longer to train. By rescaling the weights, it ensures that the dynamic range is the same for all params.</p>
</li>
<li><p>pixelwise normalization layer</p>
<p>Added after each conv layer. It normalize each activation across all channels. </p>
</li>
</ol>
<h3 id="StyleGANs"><a href="#StyleGANs" class="headerlink" title="StyleGANs"></a>StyleGANs</h3><p>People used style transfer tech in the generator to ensure that the generated images have the same local structure as the training images. The dis and the loss function were not modified. </p>
<p>Mapping network: an eight-layer MLP that maps the latent representations z to a vector w. These vectors control the style of the generated image at different levels, from fine-grained texture, to high level features. </p>
<p>Synthesis network: responsible for generating the images. It has a constant learned input. It processes this input thru multiple conv and upsampling layers. Some noise is added to the input and to all the outputs of the conv layers. Each noise layer is followed by an Adaptive Instance Normalization layer: it standardizes each feature map independently subtracting the feature map’s mean and dividing by its standard deviation. </p>
<p>The idea of adding noise independently from the codings is important. Some parts of an image are quite random. If the noise instead comes from the codings, then the generator had to dedicate a significant portion of codings’ representational power to store noise. </p>
<p>StyleGAN uses a tech called mixing regularization (style mixing), where a percentage of the generated images are produced using two different codings. This prevents the network from assuming that styles at adjacent levels are correlated. </p>

            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        Author:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Blog/about" rel="external nofollow noreferrer">csy99</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        Link:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="http://csy99.github.io/Blog/2020/07/14/hands-on-17-autoencoder/">http://csy99.github.io/Blog/2020/07/14/hands-on-17-autoencoder/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        Reprint policy:
                    </i>
                </span>
                <span class="reprint-info">
                    All articles in this blog are used except for special statements
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    reprint polocy. If reproduced, please indicate source
                    <a href="/Blog/about" target="_blank">csy99</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>Copied successfully, please follow the reprint policy of this article</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">more</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Blog/tags/DL/">
                                    <span class="chip bg-color">DL</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Blog/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,qq,wechat,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Blog/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <style>
    #reward {
        margin: 30px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.4rem;
        line-height: 38px;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 520px;
        height: 550px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 30px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

	// 调整tab距离
    #rewardModal .reward-tabs { 
        margin: 0 auto;
        width: 410px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }
	
	.reward-tabs .venmo-tab .active {
        color: #fff !important;
        background-color: #555555 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">Your recognition will motivate me!</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s4 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s4 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
						<li class="tab col s4 venmo-tab waves-effect waves-light"><a href="#venmo">Venmo</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/Blog/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/Blog/medias/reward/wechat.jpg" class="reward-img" alt="微信打赏二维码">
                    </div>
					<div id="venmo">
                        <img src="/Blog/medias/reward/venmo.jpg" class="reward-img" alt="Venmo QR code">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;Previous</div>
            <div class="card">
                <a href="/Blog/2020/07/16/hands-on-02-e2e-ml/">
                    <div class="card-image">
                        
                        
                        <img src="/Blog/medias/featureimages/9.jpg" class="responsive-img" alt="hands on: 02 e2e ml">
                        
                        <span class="card-title">hands on: 02 e2e ml</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            A piece of info fed to a ML system is called a signal. We want a high signal-to-noise ratio. 
A sequence of data process
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2020-07-16
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Blog/categories/Deep-Learning/" class="post-category">
                                    Deep Learning
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Blog/tags/DL/">
                        <span class="chip bg-color">DL</span>
                    </a>
                    
                    <a href="/Blog/tags/ML/">
                        <span class="chip bg-color">ML</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                Next&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Blog/2020/07/13/mybatis/">
                    <div class="card-image">
                        
                        
                        <img src="/Blog/medias/featureimages/22.jpg" class="responsive-img" alt="mybatis">
                        
                        <span class="card-title">mybatis</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            JDBC缺点：

非对象，修改表需要重写api。没用连接池，操作数据库需要频繁的创建和关联链接
修改sql的话需要重编译java，不利于系统维护
使用PreparedStatement预编译对变量进行编号，序号不利于维护
返回结果集需要硬编
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2020-07-13
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Blog/categories/Framework/" class="post-category">
                                    Framework
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Blog/tags/mybatis/">
                        <span class="chip bg-color">mybatis</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Blog/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="/Blog/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Blog/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Blog/libs/codeBlock/codeShrink.js"></script>


<!-- 代码块折行 -->

<style type="text/css">
code[class*="language-"], pre[class*="language-"] { white-space: pre !important; }
</style>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;TOC</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Blog/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('3'),
            headingSelector: 'h1, h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h1, h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>


<script src="https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
    MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$', '$'], ['\(', '\)']]}
    });
</script>



    <footer class="page-footer bg-color">
    
    <div class="container row center-align" style="margin-bottom: 0px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            <span id="year">2020</span>
            <a href="/Blog/about" target="_blank">csy99</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            <br>
            
            
            
            
            
            
            <span id="busuanzi_container_site_pv">
                |&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv"
                    class="white-color"></span>&nbsp;次
            </span>
            
            
            <span id="busuanzi_container_site_uv">
                |&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv"
                    class="white-color"></span>&nbsp;人
            </span>
            
            <br>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/csy99" class="tooltipped" target="_blank" data-tooltip="我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:1264629690@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=1264629690" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 1264629690" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>







</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;Search</span>
            <input type="search" id="searchInput" name="s" placeholder="Please enter a search keyword"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script src="/Blog/js/search.js"></script>
<script type="text/javascript">
$(function () {
    searchFunc("/Blog/search.xml", 'searchInput', 'searchResult');
});
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Blog/libs/materialize/materialize.min.js"></script>
    <script src="/Blog/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Blog/libs/aos/aos.js"></script>
    <script src="/Blog/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Blog/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Blog/js/matery.js"></script>

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Blog/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Blog/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    

    

    

    
    <script src="/Blog/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
