<!DOCTYPE HTML>
<html lang="en">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="hands on: 12 custom, Tech Blog">
    <meta name="description" content="">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>hands on: 12 custom | Tech Blog</title>
    <link rel="icon" type="image/jpeg" href="/Blog/medias/teemo.jpeg">

    <link rel="stylesheet" type="text/css" href="/Blog/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="/Blog/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/Blog/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/Blog/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/Blog/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/Blog/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/Blog/css/my.css">

    <script src="/Blog/libs/jquery/jquery.min.js"></script>

<meta name="generator" content="Hexo 5.1.1"><link rel="stylesheet" href="/Blog/css/prism-tomorrow.css" type="text/css"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Blog/" class="waves-effect waves-light">
                    
                    <img src="/Blog/medias/teemo.jpeg" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Tech Blog</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Blog/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>Index</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Blog/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>Tags</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Blog/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>Categories</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Blog/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>Archives</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Blog/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>About</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Blog/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>Contact</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Blog/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>Friends</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="Search" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Blog/medias/teemo.jpeg" class="logo-img circle responsive-img">
        
        <div class="logo-name">Tech Blog</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Blog/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			Index
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Blog/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			Tags
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Blog/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			Categories
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Blog/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			Archives
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Blog/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			About
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Blog/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			Contact
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Blog/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			Friends
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/csy99/Blog" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork My Blog
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/csy99/Blog" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork My Blog" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/Blog/medias/featureimages/2.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">hands on: 12 custom</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="/Blog/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        margin: 35px 0 15px 0;
        padding-left: 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        height: calc(100vh - 250px);
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;

        position: absolute;
        right: 23.5vw;
        display: block;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Blog/tags/DL/">
                                <span class="chip bg-color">DL</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Blog/categories/Deep-Learning/" class="post-category">
                                Deep Learning
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>Publish Date:&nbsp;&nbsp;
                    2020-06-18
                </div>
                

                

                

                

                
            </div>
        </div>
        <hr class="clearfix">
        <div class="card-content article-card-content">
            <div id="articleContent">
                <h1 id="Using-TF-like-Numpy"><a href="#Using-TF-like-Numpy" class="headerlink" title="Using TF like Numpy"></a>Using TF like Numpy</h1><p>A tensor is very similar to a numpy ndarray: usually a multidimensional array, but can also hold a scalar. </p>
<h3 id="Tensors-and-Operations"><a href="#Tensors-and-Operations" class="headerlink" title="Tensors and Operations"></a>Tensors and Operations</h3><p>We can create a matrix. </p>
<pre class=" language-python"><code class="language-python">mat <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
mat<span class="token punctuation">.</span>shape
mat<span class="token punctuation">.</span>dtype</code></pre>
<p>Indexing and all sorts of tensor operations work much like in numpy. </p>
<p>Some functions have a different name. For instance, tf.reduce_mean/sum/max() is equivalent to np.mean(), np.sum(), np.max(). In TF, we must write tf.transpose(mat) instead of mat.T in numpy. There is a reason. In TF, a new tensor is created with its own copy of the transposed data. </p>
<p>We can apply TF operations to numpy arrays and vice versa. </p>
<pre class=" language-python"><code class="language-python">a <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span>a<span class="token punctuation">)</span>
tf<span class="token punctuation">.</span>square<span class="token punctuation">(</span>a<span class="token punctuation">)</span></code></pre>
<p>Notice that numpy use 64 bit precision by default, while TF uses 32 bit (which runs faster and uses less RAM). When we create a tensor from a numpy array, set dtype=tf.float32. </p>
<h3 id="Type-Conversions"><a href="#Type-Conversions" class="headerlink" title="Type Conversions"></a>Type Conversions</h3><p>TF does not do type conversions automatically. Instead, it just raises an exception. For example, you cannot add a float tensor and an integer tensor, or even add a 32-bit float and a 64-bit float. Use tf.cast() to convert types. </p>
<h3 id="Variables"><a href="#Variables" class="headerlink" title="Variables"></a>Variables</h3><p>The tf.Tensor values are immutable. So we need tf.Variable to store parameters that may be changed. We can modifiy in place using the assign() method. </p>
<pre class=" language-python"><code class="language-python">v <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
v<span class="token punctuation">.</span>assign<span class="token punctuation">(</span><span class="token number">2</span><span class="token operator">*</span>v<span class="token punctuation">)</span>
v<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>assign<span class="token punctuation">(</span><span class="token number">44</span><span class="token punctuation">)</span>
v<span class="token punctuation">.</span>scatter_nd_update<span class="token punctuation">(</span>indices<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
                   updates<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span><span class="token number">200</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre>
<h3 id="Other-Data-Structures"><a href="#Other-Data-Structures" class="headerlink" title="Other Data Structures"></a>Other Data Structures</h3><p>sparse tensors: effieciently represent tensors containing mostly zeros. </p>
<p>tensor array: lists of tensors.</p>
<p>ragged tensors: static lists of lists of tensors, where every tensor has the same shape and data type. </p>
<p>string tensors: byte strings. </p>
<p>sets: manipulate using tf.sets package.</p>
<p>queues: FIFO queue, PQ, RandomShuffleQueue.</p>
<h1 id="Customizing-Models-and-Training-Alg"><a href="#Customizing-Models-and-Training-Alg" class="headerlink" title="Customizing Models and Training Alg"></a>Customizing Models and Training Alg</h1><p>Customize a loss function. </p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">huber_fn</span><span class="token punctuation">(</span>y_true<span class="token punctuation">,</span> y_pred<span class="token punctuation">)</span><span class="token punctuation">:</span>
    err <span class="token operator">=</span> y_true <span class="token operator">-</span> y_pred
    is_small_error <span class="token operator">=</span> tf<span class="token punctuation">.</span>abs<span class="token punctuation">(</span>err<span class="token punctuation">)</span> <span class="token operator">&lt;</span> <span class="token number">1</span>
    squared_loss <span class="token operator">=</span> tf<span class="token punctuation">.</span>square<span class="token punctuation">(</span>err<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2</span>
    linear_loss <span class="token operator">=</span> tf<span class="token punctuation">.</span>abs<span class="token punctuation">(</span>err<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">0.5</span>
    <span class="token keyword">return</span> tf<span class="token punctuation">.</span>where<span class="token punctuation">(</span>is_small_error<span class="token punctuation">,</span> squared_loss<span class="token punctuation">,</span> linear_loss<span class="token punctuation">)</span></code></pre>
<pre class=" language-python"><code class="language-python">model<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>loss<span class="token operator">=</span>huber_fn<span class="token punctuation">,</span> optimizer<span class="token operator">=</span><span class="token string">"nadam"</span><span class="token punctuation">)</span></code></pre>
<h3 id="saving-and-loading-customized-model"><a href="#saving-and-loading-customized-model" class="headerlink" title="saving and loading customized model"></a>saving and loading customized model</h3><p>Saving a model containing a custom loss function works fine. When we load the model, we need to map the names to the objects. </p>
<pre class=" language-python"><code class="language-python">model <span class="token operator">=</span> keras<span class="token punctuation">.</span>models<span class="token punctuation">.</span>load_model<span class="token punctuation">(</span><span class="token string">"mymodel.h5"</span><span class="token punctuation">,</span> custom_objects<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">"huber_fn"</span><span class="token punctuation">:</span> huber_fn<span class="token punctuation">}</span><span class="token punctuation">)</span></code></pre>
<p>If we create a function that creates a configured loss function, we have to specify the argument. </p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">create_huber</span><span class="token punctuation">(</span>threshold<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">huber_fn</span><span class="token punctuation">(</span>y_true<span class="token punctuation">,</span> y_pred<span class="token punctuation">)</span><span class="token punctuation">:</span>
        err <span class="token operator">=</span> y_true <span class="token operator">-</span> y_pred
        is_small_error <span class="token operator">=</span> tf<span class="token punctuation">.</span>abs<span class="token punctuation">(</span>err<span class="token punctuation">)</span> <span class="token operator">&lt;</span> threshold
        squared_loss <span class="token operator">=</span> tf<span class="token punctuation">.</span>square<span class="token punctuation">(</span>err<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2</span>
        linear_loss <span class="token operator">=</span> tf<span class="token punctuation">.</span>abs<span class="token punctuation">(</span>err<span class="token punctuation">)</span><span class="token operator">*</span>tf<span class="token punctuation">.</span>abs<span class="token punctuation">(</span>err<span class="token punctuation">)</span> <span class="token operator">-</span> threshold<span class="token operator">**</span><span class="token number">2</span><span class="token operator">/</span><span class="token number">2</span>
        <span class="token keyword">return</span> tf<span class="token punctuation">.</span>where<span class="token punctuation">(</span>is_small_error<span class="token punctuation">,</span> squared_loss<span class="token punctuation">,</span> linear_loss<span class="token punctuation">)</span>
    <span class="token keyword">return</span> huber_fn

model<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>loss<span class="token operator">=</span>create_huber<span class="token punctuation">(</span><span class="token number">2.0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> optimizer<span class="token operator">=</span><span class="token string">"nadam"</span><span class="token punctuation">)</span>

model <span class="token operator">=</span> keras<span class="token punctuation">.</span>models<span class="token punctuation">.</span>load_model<span class="token punctuation">(</span><span class="token string">"mymodel.h5"</span><span class="token punctuation">,</span> 
     custom_objects<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">"huber_fn"</span><span class="token punctuation">:</span> create_huber<span class="token punctuation">(</span><span class="token number">2.0</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">)</span></code></pre>
<p>We can also create a subclass of keras.losses.Loss. </p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">HuberLoss</span><span class="token punctuation">(</span>keras<span class="token punctuation">.</span>losses<span class="token punctuation">.</span>Loss<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> threshold<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>threshold <span class="token operator">=</span> threshold
        super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">call</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> y_true<span class="token punctuation">,</span> y_pred<span class="token punctuation">)</span><span class="token punctuation">:</span>
        err <span class="token operator">=</span> y_true <span class="token operator">-</span> y_pred
        is_small_err <span class="token operator">=</span> tf<span class="token punctuation">.</span>abs<span class="token punctuation">(</span>err<span class="token punctuation">)</span> <span class="token operator">&lt;</span> self<span class="token punctuation">.</span>threshold
        squared_loss <span class="token operator">=</span> tf<span class="token punctuation">.</span>square<span class="token punctuation">(</span>err<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2</span>
        linear_loss <span class="token operator">=</span> self<span class="token punctuation">.</span>threshold <span class="token operator">*</span> tf<span class="token punctuation">.</span>abs<span class="token punctuation">(</span>err<span class="token punctuation">)</span> <span class="token operator">-</span> self<span class="token punctuation">.</span>threshold<span class="token operator">**</span><span class="token number">2</span><span class="token operator">/</span><span class="token number">2</span>
        <span class="token keyword">return</span> tf<span class="token punctuation">.</span>where<span class="token punctuation">(</span>is_small_error<span class="token punctuation">,</span> squared_loss<span class="token punctuation">,</span> linear_loss<span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">get_config</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        base_config <span class="token operator">=</span> super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get_config<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> <span class="token punctuation">{</span><span class="token operator">**</span>base_config<span class="token punctuation">,</span> <span class="token string">"threshold"</span><span class="token punctuation">:</span>self<span class="token punctuation">.</span>threshold<span class="token punctuation">}</span></code></pre>
<p>The get_config() method returns a dictionary mapping each hyperparameter name to its value. </p>
<p>We can use any instance of this class when compiling the model.</p>
<pre class=" language-python"><code class="language-python">model<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>loss<span class="token operator">=</span>HuberLoss<span class="token punctuation">(</span><span class="token number">2.0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> optimizer<span class="token operator">=</span><span class="token string">"sgd"</span><span class="token punctuation">)</span>

model <span class="token operator">=</span> keras<span class="token punctuation">.</span>models<span class="token punctuation">.</span>load_model<span class="token punctuation">(</span><span class="token string">"mymodel.h5"</span><span class="token punctuation">,</span>
             custom_objects<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">"HuberLoss"</span><span class="token punctuation">:</span>HuberLoss<span class="token punctuation">}</span><span class="token punctuation">)</span></code></pre>
<h3 id="Custom-Other-parts"><a href="#Custom-Other-parts" class="headerlink" title="Custom Other parts"></a>Custom Other parts</h3><p>Activation functions, initializers, regularizers, and constraints. </p>
<p>Losses and metrics are conceptually not the same thing. Losses are used by GD to train a model, so they must be differentiable and their gradients should not be 0 everywhere. In contrast, metrics are used to evaluate a model, so they must be easily interpretable and have 0 gradients everywhere. </p>
<p>Streaming metric: gradually updated, batch after batch. (e.g.: it manifest overall precision so far instead of current batch).</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">HuberMetric</span><span class="token punctuation">(</span>keras<span class="token punctuation">.</span>metrics<span class="token punctuation">.</span>Metric<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> threshold<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>threshold <span class="token operator">=</span> threshold
        self<span class="token punctuation">.</span>huber_fn <span class="token operator">=</span> create_huber<span class="token punctuation">(</span>threshold<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>total <span class="token operator">=</span> self<span class="token punctuation">.</span>add_weight<span class="token punctuation">(</span><span class="token string">"total"</span><span class="token punctuation">,</span> initializer<span class="token operator">=</span><span class="token string">"zeros"</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>count <span class="token operator">=</span> self<span class="token punctuation">.</span>add_weight<span class="token punctuation">(</span><span class="token string">"count"</span><span class="token punctuation">,</span> initializer<span class="token operator">=</span><span class="token string">"zeros"</span><span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">update_state</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> y_true<span class="token punctuation">,</span> y_pred<span class="token punctuation">,</span> sample_weight<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>
        metric <span class="token operator">=</span> self<span class="token punctuation">.</span>huber_fn<span class="token punctuation">(</span>y_true<span class="token punctuation">,</span> y_pred<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>total<span class="token punctuation">.</span>assign_add<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>reduce_sum<span class="token punctuation">(</span>metric<span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>count<span class="token punctuation">.</span>assign_add<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>cast<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>size<span class="token punctuation">(</span>y_true<span class="token punctuation">)</span><span class="token punctuation">,</span> 
                                     tf<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">result</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>total<span class="token operator">/</span>self<span class="token punctuation">.</span>count
    <span class="token keyword">def</span> <span class="token function">get_config</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        base_ <span class="token operator">=</span> super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get_config<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> <span class="token punctuation">{</span><span class="token operator">**</span>base_<span class="token punctuation">,</span> <span class="token string">"threshold"</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>threshold<span class="token punctuation">}</span></code></pre>
<h3 id="Custom-Layers"><a href="#Custom-Layers" class="headerlink" title="Custom Layers"></a>Custom Layers</h3><p>If we want to create a custom layer without any weights. </p>
<pre class=" language-python"><code class="language-python">exp_layer <span class="token operator">=</span> keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Lambda<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> tf<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre>
<p>If we want to build a custom stateful layer. </p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">myDense</span><span class="token punctuation">(</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Layer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> units<span class="token punctuation">,</span> activation<span class="token operator">=</span>None<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>units <span class="token operator">=</span> units
        self<span class="token punctuation">.</span>activation <span class="token operator">=</span> keras<span class="token punctuation">.</span>activations<span class="token punctuation">.</span>get<span class="token punctuation">(</span>activation<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">build</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch_input_shape<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>kernel <span class="token operator">=</span> self<span class="token punctuation">.</span>add_weight<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">"kernel"</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">[</span>batch_input_shape<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>units<span class="token punctuation">]</span><span class="token punctuation">,</span> initializer<span class="token operator">=</span><span class="token string">"glorot_normal"</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>bias <span class="token operator">=</span> self<span class="token punctuation">.</span>add_wieght<span class="token punctuation">(</span>
            name<span class="token operator">=</span><span class="token string">"bias"</span><span class="token punctuation">,</span> 
            shape<span class="token operator">=</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>units<span class="token punctuation">]</span><span class="token punctuation">,</span> 
            initializer<span class="token operator">=</span><span class="token string">"zeros"</span>
        <span class="token punctuation">)</span>
        super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>build<span class="token punctuation">(</span>batch_input_shape<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">call</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>activation<span class="token punctuation">(</span>X@self<span class="token punctuation">.</span>kernel <span class="token operator">+</span> self<span class="token punctuation">.</span>bias<span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">compute_out_shape</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch_input_shape<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> tf<span class="token punctuation">.</span>TensorShape<span class="token punctuation">(</span>batch_input_shape<span class="token punctuation">.</span>as_list<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">+</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>units<span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">get_config</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        base <span class="token operator">=</span> super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get_config<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> <span class="token punctuation">{</span><span class="token operator">**</span>base_config<span class="token punctuation">,</span> <span class="token string">"units"</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>units<span class="token punctuation">,</span> 
               <span class="token string">"activation"</span><span class="token punctuation">:</span> keras<span class="token punctuation">.</span>activations<span class="token punctuation">.</span>serialize<span class="token punctuation">(</span>self<span class="token punctuation">.</span>activation<span class="token punctuation">)</span><span class="token punctuation">}</span></code></pre>
<p>Unless the layer is dynamic, Keras assumes the output shape is the same as the input shape. </p>
<h3 id="Losses-and-Metrics-Based-on-Model-Internals"><a href="#Losses-and-Metrics-Based-on-Model-Internals" class="headerlink" title="Losses and Metrics Based on Model Internals"></a>Losses and Metrics Based on Model Internals</h3><p>When we want to define losses based on other parts of our model. For example, reconstruction loss is the mean squared difference between the reconstruction and the inputs. By addition this to the mail loss, we will encourage the model to preserve as much info as possible through the hidden layers. It improves generalization.</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">ReconstructReg</span><span class="token punctuation">(</span>keras<span class="token punctuation">.</span>Model<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> output_dim<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>hidden <span class="token operator">=</span> <span class="token punctuation">[</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">30</span><span class="token punctuation">)</span> <span class="token keyword">for</span> _ <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>out <span class="token operator">=</span> keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span>output_dim<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">build</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch_input_shape<span class="token punctuation">)</span><span class="token punctuation">:</span>
        n_inputs <span class="token operator">=</span> batch_input_shape<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>reconstruct <span class="token operator">=</span> keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span>n_inputs<span class="token punctuation">)</span>
        super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>build<span class="token punctuation">(</span>batch_input_shape<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">call</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        Z <span class="token operator">=</span> inputs
        <span class="token keyword">for</span> layer <span class="token keyword">in</span> self<span class="token punctuation">.</span>hidden<span class="token punctuation">:</span>
            Z <span class="token operator">=</span> layer<span class="token punctuation">(</span>Z<span class="token punctuation">)</span>
        reconstruction <span class="token operator">=</span> self<span class="token punctuation">.</span>reconstruct<span class="token punctuation">(</span>Z<span class="token punctuation">)</span>
        recon_loss <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>square<span class="token punctuation">(</span>reconstruction<span class="token operator">-</span>inputs<span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>add_loss<span class="token punctuation">(</span><span class="token number">0.55</span><span class="token operator">*</span>recon_loss<span class="token punctuation">)</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>out<span class="token punctuation">(</span>Z<span class="token punctuation">)</span></code></pre>
<p>The build() method creates an extra dense layer which will be used to reconstruct the inputs. The number of inputs is unknown before the build() is called. </p>
<h3 id="Computing-Gradients-using-Autodiff"><a href="#Computing-Gradients-using-Autodiff" class="headerlink" title="Computing Gradients using Autodiff"></a>Computing Gradients using Autodiff</h3><p>When we need to find the partial derivative w/o too much trouble. </p>
<pre class=" language-python"><code class="language-python">w1<span class="token punctuation">,</span> w2 <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">,</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">)</span>
<span class="token keyword">with</span> tf<span class="token punctuation">.</span>GradientTape<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> tape<span class="token punctuation">:</span>
    z <span class="token operator">=</span> f<span class="token punctuation">(</span>w1<span class="token punctuation">,</span> w2<span class="token punctuation">)</span>
gradients <span class="token operator">=</span> tape<span class="token punctuation">.</span>gradient<span class="token punctuation">(</span>z<span class="token punctuation">,</span> <span class="token punctuation">[</span>w1<span class="token punctuation">,</span> w2<span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre>
<p>To save mem, only put the strict minimum inside the tf.GradientTape() block. The tape is auto erased immediately after we call its gradient(). So, we will get an error if we call it more than once. The solution is to make it permanent and erase it by hand. </p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">with</span> tf<span class="token punctuation">.</span>GradientTape<span class="token punctuation">(</span>persistent<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span> <span class="token keyword">as</span> tape<span class="token punctuation">:</span>
    z <span class="token operator">=</span> f<span class="token punctuation">(</span>w1<span class="token punctuation">,</span> w2<span class="token punctuation">)</span>
dz_dw1 <span class="token operator">=</span> tape<span class="token punctuation">.</span>gradient<span class="token punctuation">(</span>z<span class="token punctuation">,</span> w1<span class="token punctuation">)</span>
dz_dw2 <span class="token operator">=</span> tape<span class="token punctuation">.</span>gradient<span class="token punctuation">(</span>z<span class="token punctuation">,</span> w2<span class="token punctuation">)</span>
<span class="token keyword">del</span> tape</code></pre>
<p>By default, the tape only tracks operations involving variables. Use tape.watch() to specify something we want the tape to track.</p>
<p>In some cases, we may want to stop gradients from BP through some part of our NN. </p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">f</span><span class="token punctuation">(</span>w1<span class="token punctuation">,</span> w2<span class="token punctuation">)</span> <span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token number">3</span><span class="token operator">*</span>w1 <span class="token operator">+</span> tf<span class="token punctuation">.</span>stop_gradient<span class="token punctuation">(</span><span class="token number">2</span><span class="token operator">*</span>w1<span class="token operator">*</span>w2<span class="token punctuation">)</span></code></pre>
<h3 id="Custom-Training-Loops"><a href="#Custom-Training-Loops" class="headerlink" title="Custom Training Loops"></a>Custom Training Loops</h3><p>The fit() method is not flexible enough, e.g.: in wide&amp;deep paper. </p>
<p>//TODO</p>
<h1 id="TF-functions-and-graphs"><a href="#TF-functions-and-graphs" class="headerlink" title="TF functions and graphs"></a>TF functions and graphs</h1><p>Convert a python func to a TF func. </p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">cube</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> x<span class="token operator">**</span><span class="token number">3</span>

tf_cube <span class="token operator">=</span> tf<span class="token punctuation">.</span>function<span class="token punctuation">(</span>cube<span class="token punctuation">)</span>
tf_cub<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span></code></pre>
<p>Alternatively, we can use tf.function as a decorator. </p>
<pre class=" language-python"><code class="language-python">@tf<span class="token punctuation">.</span>funciton
<span class="token keyword">def</span> <span class="token function">tf_cube</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> x<span class="token operator">**</span><span class="token number">3</span></code></pre>
<p>When we write a custom loss function/metric/layer, Keras automatically converts our function into a TF function. </p>
<p>By default, a TF function generates a new graph for every unique set of input shapes and data types and caches it for subsequent calls. However, if we pass numerical python values, a new graph will be generated for every distinct value. </p>
<h3 id="AutoGraph-and-Tracing"><a href="#AutoGraph-and-Tracing" class="headerlink" title="AutoGraph and Tracing"></a>AutoGraph and Tracing</h3><p>AutoGraph: Python does not provide any other way to capture control flow statements, so autograph analyzes the functions’ code and outputs an upgraded version of that function. After this, control flow statements will be replaced by TF operations (e.g.: tf.while_loop()). </p>
<p>Next, TD calls this upgraded function, and passes a symbolic tensor. The function will run in graph mode, meaning each TF operation will add a node in the graph to represent itself and its output tensors. </p>
<h3 id="TF-function-rules"><a href="#TF-function-rules" class="headerlink" title="TF function rules"></a>TF function rules</h3><p>If we call any external library, including numpy or even standard library, this call will run only during tracing (will not be a part of the graph. </p>
<p>If our non-TF code has side effects (such as logging or updating a counter), we should not expect these to occur every time we call the TF function. </p>
<p>We can wrap Python code in a tf.py_function(), but this will hinder performance. In addition, it reduces portability, as the graph will only run on platforms where Python and right libraries are available . </p>
<p>If the function creates a stateful TF object (e.g.: variable), it must do so only upon the very first call, or else we will get an exception. If you want to assign a new value to the variable, use assign() rather than “=”. Use <code>for i in tf.range(x)</code> rather than <code>for i in range(x)</code>. </p>
<p>The source code of our python function should be available to TF.</p>

            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        Author:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Blog/about" rel="external nofollow noreferrer">csy99</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        Link:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="http://csy99.github.io/Blog/2020/06/18/hands-on-12-custom/">http://csy99.github.io/Blog/2020/06/18/hands-on-12-custom/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        Reprint policy:
                    </i>
                </span>
                <span class="reprint-info">
                    All articles in this blog are used except for special statements
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    reprint polocy. If reproduced, please indicate source
                    <a href="/Blog/about" target="_blank">csy99</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>Copied successfully, please follow the reprint policy of this article</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">more</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Blog/tags/DL/">
                                    <span class="chip bg-color">DL</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Blog/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,qq,wechat,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Blog/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <style>
    #reward {
        margin: 30px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.4rem;
        line-height: 38px;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 520px;
        height: 550px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 30px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

	// 调整tab距离
    #rewardModal .reward-tabs { 
        margin: 0 auto;
        width: 410px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }
	
	.reward-tabs .venmo-tab .active {
        color: #fff !important;
        background-color: #555555 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">Your recognition will motivate me!</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s4 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s4 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
						<li class="tab col s4 venmo-tab waves-effect waves-light"><a href="#venmo">Venmo</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/Blog/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/Blog/medias/reward/wechat.jpg" class="reward-img" alt="微信打赏二维码">
                    </div>
					<div id="venmo">
                        <img src="/Blog/medias/reward/venmo.jpg" class="reward-img" alt="Venmo QR code">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    
        <link rel="stylesheet" href="/Blog/libs/gitalk/gitalk.css">
<link rel="stylesheet" href="/Blog/css/my-gitalk.css">

<div class="card gitalk-card" data-aos="fade-up">
    <div class="comment_headling" style="font-size: 20px; font-weight: 700; position: relative; padding-left: 20px; top: 15px; padding-bottom: 5px;">
        <i class="fas fa-comments fa-fw" aria-hidden="true"></i>
        <span>评论</span>
    </div>
    <div id="gitalk-container" class="card-content"></div>
</div>

<script src="/Blog/libs/gitalk/gitalk.min.js"></script>
<script>
    let gitalk = new Gitalk({
        clientID: 'aecfa0a3613bd862ed5f',
        clientSecret: '7bd4e6a082f93ffb388a540481f5be3c59151255',
        repo: 'csy99.github.io',
        owner: 'csy99',
        admin: "csy99",
        id: '2020-06-18T23-57-26',
        distractionFreeMode: false  // Facebook-like distraction free mode
    });

    gitalk.render('gitalk-container');
</script>

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;Previous</div>
            <div class="card">
                <a href="/Blog/2020/06/19/hands-on-10-keras/">
                    <div class="card-image">
                        
                        
                        <img src="/Blog/medias/featureimages/14.jpg" class="responsive-img" alt="hands on: 10 keras">
                        
                        <span class="card-title">hands on: 10 keras</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Biological to Artificial NeuronsThreshold Logic Unit (TLU)input/output: numbers. compute a weighted sum of its inputs an
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2020-06-19
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Blog/categories/Deep-Learning/" class="post-category">
                                    Deep Learning
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Blog/tags/DL/">
                        <span class="chip bg-color">DL</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                Next&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Blog/2020/06/17/hands-on-11-training/">
                    <div class="card-image">
                        
                        
                        <img src="/Blog/medias/featureimages/11.jpg" class="responsive-img" alt="hands on: 11 training">
                        
                        <span class="card-title">hands on: 11 training</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Vanishing/Exploding Gradientsvanishing gradients
Gradients often get smaller and smaller as the algorithm progresses dow
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2020-06-17
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Blog/categories/Deep-Learning/" class="post-category">
                                    Deep Learning
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Blog/tags/DL/">
                        <span class="chip bg-color">DL</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Blog/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="/Blog/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Blog/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Blog/libs/codeBlock/codeShrink.js"></script>


<!-- 代码块折行 -->

<style type="text/css">
code[class*="language-"], pre[class*="language-"] { white-space: pre !important; }
</style>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;TOC</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Blog/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('3'),
            headingSelector: 'h1, h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h1, h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>




    <footer class="page-footer bg-color">
    
    <div class="container row center-align" style="margin-bottom: 0px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            <span id="year">2020</span>
            <a href="/Blog/about" target="_blank">csy99</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            <br>
            
            
            
            
            
            
            <span id="busuanzi_container_site_pv">
                |&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv"
                    class="white-color"></span>&nbsp;次
            </span>
            
            
            <span id="busuanzi_container_site_uv">
                |&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv"
                    class="white-color"></span>&nbsp;人
            </span>
            
            <br>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/csy99" class="tooltipped" target="_blank" data-tooltip="我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:1264629690@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=1264629690" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 1264629690" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>







</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;Search</span>
            <input type="search" id="searchInput" name="s" placeholder="Please enter a search keyword"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script src="/Blog/js/search.js"></script>
<script type="text/javascript">
$(function () {
    searchFunc("/Blog/search.xml", 'searchInput', 'searchResult');
});
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Blog/libs/materialize/materialize.min.js"></script>
    <script src="/Blog/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Blog/libs/aos/aos.js"></script>
    <script src="/Blog/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Blog/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Blog/js/matery.js"></script>

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Blog/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Blog/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    

    

    

    
    <script src="/Blog/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
